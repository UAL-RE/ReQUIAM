#!/usr/bin/env python

from os import path

import pandas as pd

from datetime import date

import argparse

from requiam import CODE_NAME
from requiam.grouper import Grouper, create_groups
from redata.commons import logger
from requiam import TimerClass
from requiam.commons import dict_load

# Version and branch info
from requiam import __version__
from redata.commons.git_info import GitInfo
from requiam import __file__ as library_path

today = date.today()

# Retrieve parent directory to requiam
library_root_path = path.dirname(path.dirname(library_path))


if __name__ == '__main__':
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description='Command-line driver to add a Grouper group.')
    parser.add_argument('--config', required=True, help='path to configuration file')
    parser.add_argument('--persistent_path', required=True, help='full parent path for logs')
    parser.add_argument('--grouper_host', help='Grouper host')
    parser.add_argument('--grouper_base_path', help='base path for Grouper API')
    parser.add_argument('--grouper_user', help='user name for Grouper login')
    parser.add_argument('--grouper_password', help='password for Grouper login')
    parser.add_argument('--main_themes', action='store_true', help='Add/update main themes')
    parser.add_argument('--sub_portals', action='store_true', help='Add/update sub-portals')
    parser.add_argument('--quota', action='store_true', help='Add/update quotas')
    parser.add_argument('--production', action='store_true',
                        help='perform on Grouper production stem. Default: on stage stem')
    parser.add_argument('--add', action='store_true', help='perform add')
    parser.add_argument('--debug', action='store_true', help='turn on debug logging')
    args = parser.parse_args()
    vargs = vars(args)

    gi = GitInfo(input_path=library_root_path)

    banner_message = f"""
    This is the command-line tool to create Grouper groups for main themes, sub-portals, and quotas.
    A full execution will:
     1. Check whether the group exists
     2. Create the group
     3. Set permissions for GrouperSuperAdmins and GrouperAdmins

    {CODE_NAME} active branch: {gi.branch}
    {CODE_NAME} version: {__version__}
    {CODE_NAME} commit hash: {gi.short_commit}
    Created by Chun Ly
    Issues/Suggestions? Submit a GitHub ticket: https://github.com/UAL-RE/ReQUIAM/issues/new/choose
    """
    print(banner_message)

    main_timer = TimerClass()
    main_timer._start()

    config_dict = dict_load(args.config, vargs=vargs)
    global_dict = config_dict['global']  # These are settings in args.config
    extras_dict = config_dict['extras']  # These are settings specific to script not in args.config

    # Define logfile
    log_dir = path.join(global_dict['persistent_path'], global_dict['log_dir'])
    logfile_prefix = 'add_grouper_groups'
    log = logger.log_setup(log_dir, logfile_prefix)

    lc = logger.LogCommons(log, 'add_grouper_group', gi,
                           code_name=CODE_NAME, version=__version__)
    lc.script_start()

    # Retrieve username, hostname, IP
    lc.script_sys_info()

    protected_keys = ['grouper_user', 'grouper_password']
    cred_err = logger.log_settings(vargs, config_dict, protected_keys,
                                   log=log)

    if cred_err:
        log.warning("Not all credentials available!")
        log.warning("Exiting")
        raise ValueError

    grouper_keys = ['grouper_'+suffix for
                    suffix in ['host', 'base_path', 'user', 'password']]
    grouper_dict = {x: global_dict[x] for x in grouper_keys}

    if extras_dict['production']:
        grouper_production = True
    else:
        grouper_production = False

    ga = Grouper(**grouper_dict, grouper_production=grouper_production,
                 log=log)

    # Main portals / Overall Research Themes
    if extras_dict['main_themes']:
        mainTheme_timer = TimerClass()
        mainTheme_timer._start()

        # Read in Google Sheet CSV with main themes
        mainTheme_url = config_dict['google']['maintheme_url']
        log.info("Reading Main Theme CSV into DataFrame ...")
        mainTheme_df = pd.read_csv(mainTheme_url)

        # Drop empty rows
        mainTheme_df = mainTheme_df.dropna(axis=0, how='all')

        # Limit to those with Create set
        mainTheme_df_excluded = mainTheme_df.loc[mainTheme_df['Create?'] != 'Yes']
        mainTheme_excluded_dict = mainTheme_df_excluded.set_index('Main-portal').T.to_dict()
        log.info(f"Excluded main themes: {', '.join(list(mainTheme_excluded_dict.keys()))}")

        mainTheme_df = mainTheme_df.loc[mainTheme_df['Create?'] == 'Yes']

        # Construction dict with main portal names
        mainTheme_dict = mainTheme_df.set_index('Main-portal').T.to_dict()

        main_groups = list(mainTheme_dict.keys())
        main_descriptions = mainTheme_df['Grouper Description'].to_list()

        n_mainThemes = len(main_groups)
        log.info(f"Total number of main themes: {n_mainThemes}")
        log.info(f"List of main themes: {', '.join(main_groups)}")

        create_groups(main_groups, 'portal', main_descriptions, ga, log0=log,
                      add=extras_dict['add'])

        mainTheme_timer._stop()
        log.info(f"MAIN PORTAL : {mainTheme_timer.format}")

    # Sub-portals
    if extras_dict['sub_portals']:
        subPortal_timer = TimerClass()
        subPortal_timer._start()

        # Read in Google Sheet CSV with sub-portals
        subPortal_url = config_dict['google']['subportal_url']
        log.info("Reading Sub-portals CSV into DataFrame ...")
        subPortal_df = pd.read_csv(subPortal_url)

        # Drop empty rows
        subPortal_df = subPortal_df.dropna(axis=0, how='all')

        # Limit to those with Create set
        subPortal_df_excluded = subPortal_df.loc[subPortal_df['Create?'] != 'Yes']
        subPortal_excluded_dict = subPortal_df_excluded.set_index('Sub-portal').T.to_dict()
        log.info(f"Excluded sub-portals: {', '.join(list(subPortal_excluded_dict.keys()))}")

        subPortal_df = subPortal_df.loc[subPortal_df['Create?'] == 'Yes']

        # Construction dict with sub-portal names
        subPortal_dict = subPortal_df.set_index('Sub-portal').T.to_dict()

        sub_groups = list(subPortal_dict.keys())
        sub_descriptions = subPortal_df['Grouper Description'].to_list()

        n_subPortals = len(sub_groups)
        log.info(f"Total number of sub-portals: {n_subPortals}")
        log.info(f"List of sub-portals: {', '.join(sub_groups)}")

        create_groups(sub_groups, 'portal', sub_descriptions, ga, log0=log,
                      add=extras_dict['add'])

        subPortal_timer._stop()
        log.info(f"SUB-PORTAL : {subPortal_timer.format}")

    # Quotas
    if extras_dict['quota']:
        quota_timer = TimerClass()
        quota_timer._start()

        # Read in Google Sheet CSV with sub-portals
        quota_url = config_dict['google']['quota_url']
        log.info("Reading Quotas CSV into DataFrame ...")
        quota_df = pd.read_csv(quota_url)

        # Drop empty rows
        quota_df = quota_df.dropna(axis=0, how='all')

        # Limit to those with Create set
        quota_df_excluded = quota_df.loc[quota_df['Create?'] != 'Yes']
        quota_excluded_groups = quota_df_excluded['Quota'].astype(str).to_list()
        log.info(f"Excluded quotas: {', '.join(quota_excluded_groups)}")

        quota_df = quota_df.loc[quota_df['Create?'] == 'Yes']

        # Read in list of quotas
        quota_groups = quota_df['Quota'].astype(str).to_list()
        quota_descriptions = quota_df['Grouper Description'].to_list()

        n_quotas = len(quota_groups)
        log.info(f"Total number of quotas: {n_quotas}")
        log.info(f"List of quotas: {', '.join(quota_groups)}")

        create_groups(quota_groups, 'quota', quota_descriptions, ga, log0=log,
                      add=extras_dict['add'])

        quota_timer._stop()
        log.info(f"QUOTA : {quota_timer.format}")

    main_timer._stop()
    log.info(main_timer.format)

    lc.script_end()

    lc.log_permission()
