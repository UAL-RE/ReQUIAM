#!/user/bin/env python

from os import path, chmod
from os import mkdir

import pandas as pd

from datetime import date

import configparser
import argparse

import ast

from requiam import ldap_query
from requiam.grouper_query import GrouperQuery, figshare_group
from requiam.grouper_admin import GrouperAPI, create_active_group
from requiam import delta
from requiam import quota
from requiam.logger import LogClass, get_user_hostname, pandas_write_buffer
from requiam import TimerClass
from requiam import manual_override

# Version and branch info
from requiam import __version__
from requiam.git_info import get_active_branch_name, get_latest_commit
from requiam import __file__ as library_path

today = date.today()

library_root_path = path.dirname(path.dirname(library_path))  # Retrieve parent directory to requiam


if __name__ == '__main__':
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description='Command-line driver for figshare patron management.')
    parser.add_argument('--config', required=True, help='path to configuration file')
    parser.add_argument('--persistent_path', required=True, help='full parent path for logs')
    parser.add_argument('--ldap_host', help='LDAP host')
    parser.add_argument('--ldap_base_dn', help='base DN for LDAP bind and query')
    parser.add_argument('--ldap_user', help='user name for LDAP login')
    parser.add_argument('--ldap_password', help='password for LDAP login')
    parser.add_argument('--grouper_host', help='Grouper host')
    parser.add_argument('--grouper_base_path', help='base path for Grouper API')
    parser.add_argument('--grouper_user', help='user name for Grouper login')
    parser.add_argument('--grouper_password', help='password for Grouper login')
    parser.add_argument('--grouper_figtest', action='store_true', help='Flag to use testing stem')
    parser.add_argument('--batch_size', help='synchronization batch size')
    parser.add_argument('--batch_timeout', help='synchronization batch timeout in seconds')
    parser.add_argument('--batch_delay', help='delay between batches in seconds')
    parser.add_argument('--portal', action='store_true', help='perform portal queries')
    parser.add_argument('--quota', action='store_true', help='perform quota queries')
    parser.add_argument('--test', action='store_true', help='perform test query')
    parser.add_argument('--test_reverse', action='store_true', help='reverse test query (i.e., remove from Grouper)')
    parser.add_argument('--org_codes',
                        help='''List of org codes (comma separated) to implement.
                                Only set org_codes or groups. Not both''')
    parser.add_argument('--groups',
                        help='''List of portals/themes (comma separated) to implement.
                                Only set org_codes or groups. Not both''')
    parser.add_argument('--portal_file', help='filename for manual-override portal file')
    parser.add_argument('--quota_file', help='filename for manual-override quota file')
    parser.add_argument('--sync', action='store_true', help='perform synchronization')
    parser.add_argument('--sync_max', help='maximum membership delta to allow when synchronizing')
    parser.add_argument('--debug', action='store_true', help='turn on debug logging')
    args = parser.parse_args()

    branch_name = get_active_branch_name(library_root_path)
    git_commit, git_short_commit = get_latest_commit(library_root_path)

    banner_message = f"""
    This is the command-line tool that automates Grouper patron management.
    A full execution will update users' ismemberof attributes for:
     1. figshare:portal (--portal set) and
     2. figshare:quota  (--quota set)

    ReQUIAM active branch: {branch_name}
    ReQUIAM version: {__version__}
    ReQUIAM commit hash: {git_short_commit}
    Created by Chun Ly
    Issues? Submit a GitHub ticket: https://github.com/ualibraries/ReQUIAM/issues/new
    """
    print(banner_message)

    main_timer = TimerClass()
    main_timer._start()

    config = configparser.ConfigParser()
    config.read(args.config)

    # Define logfile
    log_dir = path.join(args.persistent_path, config.get('global', 'log_dir'))

    if not path.exists(log_dir):
        mkdir(log_dir)
    logfile_prefix = config.get('global', 'logfile_prefix')
    logfile = f'{logfile_prefix}.{today.strftime("%Y-%m-%d")}.log'

    log_filename = path.join(log_dir, logfile)  # Full log filename path
    log = LogClass(log_dir, logfile).get_logger()

    log.info("******************************")
    log.info("Started script_run script ... ")
    log.debug(f"ReQUIAM active branch: {branch_name}")
    log.debug(f"ReQUIAM version: {__version__} ({git_short_commit})")
    log.debug(f"ReQUIAM commit hash: {git_commit}")

    # Retrieve username, hostname, IP
    sys_info = get_user_hostname()
    log.debug(f"username : {sys_info['user']}")
    log.debug(f"hostname : {sys_info['hostname']}")
    log.debug(f"IP Addr  : {sys_info['ip']}")
    log.debug(f"Op. Sys. : {sys_info['os']}")

    cred_err = 0
    vargs = vars(args)
    for p in ['persistent_path', 'ldap_host', 'ldap_base_dn', 'ldap_user', 'ldap_password',
              'grouper_host', 'grouper_base_path', 'grouper_user', 'grouper_password',
              'grouper_figtest', 'batch_size', 'batch_timeout', 'batch_delay',
              'portal', 'quota', 'portal_file', 'quota_file',
              'test', 'test_reverse', 'org_codes',
              'groups', 'sync_max']:

        if (p in vargs) and (vargs[p] is not None):
            vargs[p] = vargs[p]
        elif (p in config['global']) and (config['global'][p] is not None) and \
                (config['global'][p] != "***override***"):
            vargs[p] = config['global'][p]
        else:
            vargs[p] = '(unset)'

        if p in ['ldap_user', 'ldap_password', 'grouper_user', 'grouper_password']:
            if vargs[p] is '(unset)':
                log.info('   {0: >17} = (unset)'.format(p))
                cred_err += 1
            else:
                log.info('   {0: >17} = (set)'.format(p))
        else:
            log.info('   {0: >17} = {1:}'. format(p, vargs[p]))

    if vargs['test'] and vargs['test_reverse']:
        log.warning("Cannot provide --test and --test_reverse")
        log.warning("Exiting")
        raise ValueError

    if cred_err:
        log.warning("Not all credentials available!")
        log.warning("Exiting")
        raise ValueError

    log.info('org_codes = %s', args.org_codes)
    log.info('   groups = %s', args.groups)
    log.info('     sync = %s', args.sync)
    log.info('    debug = %s', args.debug)

    org_codes = None  # Initialize before --org_codes or --groups

    if vargs['org_codes'] != "(unset)" and vargs['groups'] != "(unset)":
        log.warning("Cannot provide --org_codes and --groups")
        log.warning("Exiting")
        raise ValueError

    try:
        mo = manual_override.ManualOverride(vargs['portal_file'], vargs['quota_file'],
                                            log=log)
        mo_status = True
    except ValueError:
        log.warning("Unable to find manual CSV configuration files")
        log.warning("Skipping manual handling")
        mo_status = False

    # Initiate LDAP connection
    ldc = ldap_query.LDAPConnection(ldap_host=vargs['ldap_host'],
                                    ldap_base_dn=vargs['ldap_base_dn'],
                                    ldap_user=vargs['ldap_user'],
                                    ldap_password=vargs['ldap_password'],
                                    log=log)

    grouper_dict = dict(grouper_host=vargs['grouper_host'],
                        grouper_base_path=vargs['grouper_base_path'],
                        grouper_user=vargs['grouper_user'],
                        grouper_password=vargs['grouper_password'])

    delta_dict = dict(batch_size=int(vargs['batch_size']),
                      batch_timeout=int(vargs['batch_timeout']),
                      batch_delay=int(vargs['batch_delay']),
                      sync_max=int(vargs['sync_max']))

    # This is for checking whether the group exists
    grouper_production = True if not vargs['grouper_figtest'] else False
    ga = GrouperAPI(**grouper_dict, grouper_production=True, log=log)

    if not args.sync:
        log.info("dry run, not creating figtest:group_active group")
    else:
        if vargs['org_codes'] != "(unset)" or vargs['groups'] != "(unset)":
            log.info("PROMPT: Do you want to create a new group_active group?...")
            group_prompt = input("PROMPT: Answer Yes/yes. Anything else results in skip")
            log.info(f"RESPONSE: {group_prompt}")

            if not group_prompt.lower() == 'yes':
                log.info("PROMPT: What is the existing group name to user?...")
                group_name = input("PROMPT: ")
                log.info(f"RESPONSE: {group_name}")
            else:
                log.info("Creating figtest:group_active group")
                log.info("PROMPT: Provide the name for group...")
                group_name = input("PROMPT: ")
                log.info(f"RESPONSE: {group_name}")

                log.info("PROMPT: Provide the description for group...")
                group_description = input("PROMPT: ")
                log.info(f"RESPONSE: {group_description}")

                create_active_group(group_name, grouper_dict,
                                    group_description=group_description,
                                    log=log, add=args.sync)

    # Perform EDS-Grouper synchronization for figshare research portals
    if args.portal:
        portal_timer = TimerClass()
        portal_timer._start()

        # Read in CSV file
        csv_url = config.get('global', 'csv_url')
        df = pd.read_csv(csv_url)

        if args.org_codes != "(unset)":
            log.info(f"Filtering for org codes : {args.org_codes}")
            org_codes = args.org_codes.split(',')
            df = df[df['Org Code'].isin(org_codes)]

        if args.groups != "(unset)":
            log.info(f"Filtering for portals/themes : {args.groups}")
            df = df[df['Sub-portals'].isin(args.groups.split(','))]
            org_codes = df['Org Code'].to_list()

        # Add to group_active group
        if not args.sync:
            log.info('dry run, not performing sync on figtest:group_active group')
        else:
            if vargs['org_codes'] != "(unset)" or vargs['groups'] != "(unset)":
                ldap_queries = ldap_query.ual_ldap_queries(org_codes)
                ldap_members = ldap_query.ldap_search(ldc, ldap_queries)
                log.info(f" EDS size {len(ldap_members)}")

                grouper_portal = figshare_group(group_name, 'group_active',
                                                production=False)
                log.info(f"Grouper group : {grouper_portal}")
                gq = GrouperQuery(**grouper_dict, grouper_group=grouper_portal,
                                  log=log)
                log.info(f" Grouper size {len(gq.members)}")

                d = delta.Delta(ldap_members=ldap_members,
                                grouper_query_instance=gq,
                                **delta_dict,
                                log=log)

                log.info(f'ldap and grouper have {len(d.common)} members in common')
                log.info(f'synchronization will drop {len(d.drops)} entries from grouper group')
                log.info(f'synchronization will add {len(d.adds)} entries to grouper group')

                log.info('synchronizing ...')
                d.synchronize()

        if df.empty:
            log.warning("Empty portal DataFrame. Skipping portal!")
        else:
            unique_portals = df['Sub-portals'].unique()
            unique_portals_name = df['Research Themes'].unique()

            # Loop over sub-portals
            for portal, portal_name in zip(unique_portals, unique_portals_name):
                log.info("Working on {} ({}) portal".format(portal_name, portal))

                group_check = ga.check_group_exists(portal, 'portal')
                if not group_check:  # Avoid execution
                    log.warning(f"!!! Grouper portal NOT found : {portal} !!!")
                    continue

                log.info(f"Grouper portal exists : {portal}")

                df_sub = df.loc[df['Sub-portals'] == portal]

                pandas_write_buffer(df_sub, log_filename)

                # Get list of org codes for [portal]
                org_code_list = df_sub['Org Code']

                org_name_list = df_sub['Departments/Colleges/Labs/Centers']

                # LDAP query to retrieve members
                ldap_queries = ldap_query.ual_ldap_queries(org_code_list)

                ldap_members = ldap_query.ldap_search(ldc, ldap_queries)

                # Update based on CSV manual input files
                if mo_status:
                    ldap_members = mo.identify_changes(ldap_members, portal, 'portal')
                log.info(" EDS size {}".format(len(ldap_members)))

                # Grouper query
                grouper_portal = figshare_group(portal, 'portal',
                                                production=grouper_production)
                log.info(f"Grouper group : {grouper_portal}")
                gq = GrouperQuery(**grouper_dict, grouper_group=grouper_portal,
                                  log=log)
                log.info(" Grouper size {}".format(len(gq.members)))

                d = delta.Delta(ldap_members=ldap_members,
                                grouper_query_instance=gq,
                                **delta_dict,
                                log=log)

                log.info('ldap and grouper have {} members in common'.format(len(d.common)))
                log.info('synchronization will drop {} entries from grouper group'.format(len(d.drops)))
                log.info('synchronization will add {} entries to grouper group'.format(len(d.adds)))

                if args.sync:
                    log.info('synchronizing ...')
                    d.synchronize()
                else:
                    log.info('dry run, not performing synchronization')

        portal_timer._stop()
        log.info("PORTAL : " + portal_timer.format)

    # Perform EDS-Grouper synchronization for figshare quota
    if args.quota:
        quota_timer = TimerClass()
        quota_timer._start()

        quota_list  = ast.literal_eval(config['global']['quota_list'])
        quota_class = ast.literal_eval(config['global']['quota_class'])

        for q, c in zip(quota_list, quota_class):
            if 'ugrad' in c:
                log.info(f"Quota execution not required for {c} group. Skipping...")
                continue

            log.info("Working on {} quota : {} bytes".format(c, q))

            group_check = ga.check_group_exists(str(q), 'quota')
            if not group_check:  # Avoid execution
                log.warning(f"!!! Grouper quota NOT found : {q} !!!")
                continue

            log.info(f"Grouper quota exists : {q}")

            # LDAP query to retrieve members
            ldap_queries = quota.ual_ldap_quota_query(c, org_codes=org_codes)
            ldap_members = ldap_query.ldap_search(ldc, ldap_queries)

            # Update based on CSV manual input files
            if mo_status:
                ldap_members = mo.identify_changes(ldap_members, q, 'quota')
            log.info(" EDS size {}".format(len(ldap_members)))

            # Grouper query
            grouper_quota = figshare_group(q, 'quota', production=grouper_production)
            log.info(f"Grouper group : {grouper_quota}")
            gq = GrouperQuery(**grouper_dict, grouper_group=grouper_quota, log=log)
            log.info(" Grouper size {}".format(len(gq.members)))

            # Delta between LDAP and Grouper
            d = delta.Delta(ldap_members=ldap_members,
                            grouper_query_instance=gq,
                            **delta_dict,
                            log=log)

            log.info('ldap and grouper have {} members in common'.format(len(d.common)))
            log.info('synchronization will drop {} entries from grouper group'.format(len(d.drops)))
            log.info('synchronization will add {} entries to grouper group'.format(len(d.adds)))

            if args.sync:
                log.info('synchronizing ...')
                d.synchronize()
            else:
                log.info('dry run, not performing synchronization')

        quota_timer._stop()
        log.info("QUOTA : "+quota_timer.format)

    # Perform EDS-Grouper synchronization for simple test
    if args.test or args.test_reverse:
        test_timer = TimerClass()
        test_timer._start()

        log.info("Working on test sync")

        # LDAP query to retrieve members
        test_uid = config.get('global', 'uid')
        ldap_queries = ldap_query.uid_query(test_uid)
        log.info(" test account : {}".format(test_uid))

        ldap_members = set()
        if args.test:
            ldap_members = ldap_query.ldap_search(ldc, ldap_queries)
            log.info(" EDS size {}".format(len(ldap_members)))
        if args.test_reverse:
            log.info(" Providing empty member list")

        # Note testing is only performed on figshare:test and not figtest:test
        grouper_test = figshare_group('test', '')
        gq = GrouperQuery(**grouper_dict, grouper_group=grouper_test, log=log)
        log.info(" Grouper size {}".format(len(gq.members)))

        # Delta between LDAP and Grouper
        d = delta.Delta(ldap_members=ldap_members, grouper_query_instance=gq,
                        **delta_dict, log=log)

        log.info('ldap and grouper have {} members in common'.format(len(d.common)))
        log.info('synchronization will drop {} entries from grouper group'.format(len(d.drops)))
        log.info('synchronization will add {} entries to grouper group'.format(len(d.adds)))

        if args.sync:
            log.info('synchronizing ...')
            d.synchronize()
        else:
            log.info('dry run, not performing synchronization')

        test_timer._stop()
        log.info("TEST_SYNC : "+test_timer.format)

    main_timer._stop()
    log.info(main_timer.format)

    log.info("******************************")
    log.info("Exit 0")

    chmod(path.join(log_dir, logfile), mode=0o666)
