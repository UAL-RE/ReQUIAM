#!/usr/bin/env python

from os import path
from os import mkdir

import pandas as pd

from datetime import date

import argparse

import ast

from requiam import ldap_query
from requiam.grouper import Grouper, create_active_group
from requiam import delta
from requiam import quota
from requiam.logger import LogClass, LogCommons, pandas_write_buffer, log_settings
from requiam import TimerClass
from requiam import manual_override
from requiam.commons import dict_load, get_summary_dict, figshare_group

# Version and branch info
from requiam import __version__
from requiam.git_info import get_active_branch_name, get_latest_commit
from requiam import __file__ as library_path

today = date.today()

library_root_path = path.dirname(path.dirname(library_path))  # Retrieve parent directory to requiam


if __name__ == '__main__':
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description='Command-line driver for figshare patron management.')
    parser.add_argument('--config', required=True, help='path to configuration file')
    parser.add_argument('--persistent_path', required=True, help='full parent path for logs')
    parser.add_argument('--ldap_host', help='LDAP host')
    parser.add_argument('--ldap_base_dn', help='base DN for LDAP bind and query')
    parser.add_argument('--ldap_user', help='user name for LDAP login')
    parser.add_argument('--ldap_password', help='password for LDAP login')
    parser.add_argument('--grouper_host', help='Grouper host')
    parser.add_argument('--grouper_base_path', help='base path for Grouper API')
    parser.add_argument('--grouper_user', help='user name for Grouper login')
    parser.add_argument('--grouper_password', help='password for Grouper login')
    parser.add_argument('--grouper_figtest', action='store_true', help='Flag to use testing stem')
    parser.add_argument('--batch_size', help='synchronization batch size')
    parser.add_argument('--batch_timeout', help='synchronization batch timeout in seconds')
    parser.add_argument('--batch_delay', help='delay between batches in seconds')
    parser.add_argument('--portal', action='store_true', help='perform portal queries')
    parser.add_argument('--quota', action='store_true', help='perform quota queries')
    parser.add_argument('--test', action='store_true', help='perform test query')
    parser.add_argument('--test_reverse', action='store_true', help='reverse test query (i.e., remove from Grouper)')
    parser.add_argument('--org_codes',
                        help='''List of org codes (comma separated) to implement.
                                Only set org_codes or groups. Not both''')
    parser.add_argument('--groups',
                        help='''List of portals/themes (comma separated) to implement.
                                Only set org_codes or groups. Not both''')
    parser.add_argument('--portal_file', help='filename for manual-override portal file')
    parser.add_argument('--quota_file', help='filename for manual-override quota file')
    parser.add_argument('--sync', action='store_true', help='perform synchronization')
    parser.add_argument('--sync_max', help='maximum membership delta to allow when synchronizing')
    parser.add_argument('--ci', action='store_true', help='Flag for CI build tests')
    parser.add_argument('--debug', action='store_true', help='turn on debug logging')
    args = parser.parse_args()
    vargs = vars(args)

    branch_name = get_active_branch_name(library_root_path)
    git_commit, git_short_commit = get_latest_commit(library_root_path)

    banner_message = f"""
    This is the command-line tool that automates Grouper patron management.
    A full execution will update users' ismemberof attributes for:
     1. figshare:portal (--portal set) and
     2. figshare:quota  (--quota set)

    ReQUIAM active branch: {branch_name}
    ReQUIAM version: {__version__}
    ReQUIAM commit hash: {git_short_commit}
    Created by Chun Ly
    Issues? Submit a GitHub ticket: https://github.com/ualibraries/ReQUIAM/issues/new
    """
    print(banner_message)

    main_timer = TimerClass()
    main_timer._start()

    config_dict = dict_load(args.config, vargs=vargs)
    global_dict = config_dict['global']  # These are settings in args.config
    extras_dict = config_dict['extras']  # These are settings specific to script not in args.config

    # Define logfile
    log_dir = path.join(global_dict['persistent_path'], global_dict['log_dir'])
    if not path.exists(log_dir):
        mkdir(log_dir)
    logfile_prefix = global_dict['logfile_prefix']
    logfile = f'{logfile_prefix}.{today.strftime("%Y-%m-%d")}.log'

    log_filename = path.join(log_dir, logfile)  # Full log filename path
    log = LogClass(log_dir, logfile).get_logger()

    lc = LogCommons(log, 'script_run')

    lc.script_start(branch_name, git_short_commit, git_commit)

    # Retrieve username, hostname, IP
    lc.script_sys_info()

    protected_keys = ['ldap_user', 'ldap_password',
                      'grouper_user', 'grouper_password']
    cred_err = log_settings(vargs, config_dict, protected_keys, log=log)

    if extras_dict['test'] and extras_dict['test_reverse']:
        log.warning("Cannot provide --test and --test_reverse")
        log.warning("Exiting")
        raise ValueError

    if cred_err:
        log.warning("Not all credentials available!")
        log.warning("Exiting")
        raise ValueError

    org_codes = None  # Initialize before --org_codes or --groups
    if (extras_dict['org_codes'] != "(unset)") and \
            (extras_dict['groups'] != "(unset)"):
        log.warning("Cannot provide --org_codes and --groups")
        log.warning("Exiting")
        raise ValueError

    try:
        mo = manual_override.ManualOverride(global_dict['portal_file'],
                                            global_dict['quota_file'],
                                            log=log)
        mo_status = True
    except ValueError:
        log.warning("Unable to find manual CSV configuration files")
        log.warning("Skipping manual handling")
        mo_status = False

    # Initiate LDAP connection
    ldap_keys = [key for key in global_dict.keys() if 'ldap_' in key]
    ldap_dict = {x: global_dict[x] for x in ldap_keys}
    ldc = ldap_query.LDAPConnection(**ldap_dict, log=log)

    grouper_keys = ['grouper_'+suffix for
                    suffix in ['host', 'base_path', 'user', 'password']]
    grouper_dict = {x: global_dict[x] for x in grouper_keys}

    delta_keys = ['batch_size', 'batch_timeout', 'batch_delay', 'sync_max']
    delta_dict = {x: global_dict[x] for x in delta_keys}

    # This is for checking whether the group exists
    grouper_production = True if not extras_dict['grouper_figtest'] else False
    ga = Grouper(**grouper_dict, grouper_production=grouper_production, log=log)

    summary_dict = dict()  # Initialize

    if extras_dict['org_codes'] != "(unset)" or extras_dict['groups'] != "(unset)":
        if not extras_dict['sync']:
            log.info("dry run, not creating figtest:group_active group")
        else:
            log.info("PROMPT: Do you want to create a new group_active group?...")
            group_prompt = input("PROMPT: Answer Yes/yes. Anything else results in skip ")
            log.info(f"RESPONSE: {group_prompt}")

            if not group_prompt.lower() == 'yes':
                log.info("PROMPT: What is the existing group name to user?...")
                group_name = input("PROMPT: ")
                log.info(f"RESPONSE: {group_name}")
            else:
                log.info("Creating figtest:group_active group")
                log.info("PROMPT: Provide the name for group...")
                group_name = input("PROMPT: ")
                log.info(f"RESPONSE: {group_name}")

                log.info("PROMPT: Provide the description for group...")
                group_description = input("PROMPT: ")
                log.info(f"RESPONSE: {group_description}")

                create_active_group(group_name, grouper_dict,
                                    group_description=group_description,
                                    log=log, add=extras_dict['sync'])

    # Perform EDS-Grouper synchronization for figshare research portals
    if extras_dict['portal']:
        log.info("STAGE: PORTAL")
        portal_timer = TimerClass()
        portal_timer._start()

        # Read in CSV file
        csv_url = global_dict['csv_url']
        df = pd.read_csv(csv_url)

        if extras_dict['org_codes'] != "(unset)":
            log.info(f"Filtering for org codes : {extras_dict['org_codes']}")
            org_codes = extras_dict['org_codes'].split(',')
            df = df[df['Org Code'].isin(org_codes)]

        if extras_dict['groups'] != "(unset)":
            log.info(f"Filtering for portals/themes : {extras_dict['groups']}")
            df = df[df['Sub-portals'].isin(extras_dict['groups'].split(','))]
            org_codes = df['Org Code'].to_list()

        # Add to group_active group
        if extras_dict['org_codes'] != "(unset)" or extras_dict['groups'] != "(unset)":
            if not extras_dict['sync']:
                log.info('dry run, not performing sync on figtest:group_active group')
            else:
                ldap_queries = ldap_query.ual_ldap_queries(org_codes)
                ldap_members = ldap_query.ldap_search(ldc, ldap_queries)
                log.info(f" EDS size {len(ldap_members)}")

                grouper_portal = figshare_group(group_name, 'group_active',
                                                production=False)
                log.info(f"Grouper group : {grouper_portal}")

                grouper_query_dict = ga.query(grouper_portal)
                log.info(f" Grouper size {len(grouper_query_dict['members'])}")

                d = delta.Delta(ldap_members=ldap_members,
                                grouper_query_dict=grouper_query_dict,
                                **delta_dict,
                                log=log)

                log.info(f"ldap and grouper have {len(d.common)} members in common")
                log.info(f"synchronization will drop {len(d.drops)} entries from grouper group")
                log.info(f"synchronization will add {len(d.adds)} entries to grouper group")
                if not extras_dict['ci']:
                    if (len(d.drops) < 20) and (len(d.drops) > 0):
                        log.info(f"drops : {list(d.drops)}")
                    if (len(d.adds) < 20) and (len(d.adds) > 0):
                        log.info(f"adds  : {list(d.adds)}")

                if len(d.drops) + len(d.adds) > 0:
                    log.info('synchronizing ...')
                    d.synchronize()
                else:
                    log.info("synchronizing not needed")

        if df.empty:
            log.warning("Empty portal DataFrame. Skipping portal!")
        else:
            unique_portals = df['Sub-portals'].unique()
            unique_portals_name = df['Research Themes'].unique()

            # Loop over sub-portals
            for portal, portal_name in zip(unique_portals, unique_portals_name):
                log.info(f"Working on {portal_name} ({portal}) portal")

                group_check = ga.check_group_exists(portal, 'portal')
                if not group_check:  # Avoid execution
                    log.warning(f"!!! Grouper portal NOT found : {portal} !!!")
                    continue

                log.info(f"Grouper portal exists : {portal}")

                df_sub = df.loc[df['Sub-portals'] == portal]

                pandas_write_buffer(df_sub, log_filename)

                # Get list of org codes for [portal]
                org_code_list = df_sub['Org Code']

                org_name_list = df_sub['Departments/Colleges/Labs/Centers']

                # LDAP query to retrieve members
                ldap_queries = ldap_query.ual_ldap_queries(org_code_list)

                ldap_members = ldap_query.ldap_search(ldc, ldap_queries)
                log.info(f"EDS before {len(ldap_members)}")
                # Update based on CSV manual input files
                if mo_status:
                    ldap_members = mo.identify_changes(ldap_members, portal, 'portal')
                log.info(f" EDS size {len(ldap_members)}")

                # Grouper query
                grouper_portal = figshare_group(portal, 'portal',
                                                production=grouper_production)
                log.info(f"Grouper group : {grouper_portal}")
                grouper_query_dict = ga.query(grouper_portal)
                log.info(f" Grouper size {len(grouper_query_dict['members'])}")

                # For --org_codes or --groups, only add users
                if not isinstance(org_codes, type(None)):
                    log.info("Special mode with --org_codes --groups. Adding users only")
                    # Combine grouper members with new ldap members
                    ldap_members = set.union(grouper_query_dict['members'], ldap_members)

                d = delta.Delta(ldap_members=ldap_members,
                                grouper_query_dict=grouper_query_dict,
                                **delta_dict,
                                log=log)

                summary_dict[portal] = \
                    get_summary_dict(ldap_members, grouper_query_dict['members'],
                                     d)

                log.info(f"ldap and grouper have {len(d.common)} members in common")
                log.info(f"synchronization will drop {len(d.drops)} entries from grouper group")
                log.info(f"synchronization will add {len(d.adds)} entries to grouper group")
                if not extras_dict['ci']:
                    if (len(d.drops) < 20) and (len(d.drops) > 0):
                        log.info(f"drops : {list(d.drops)}")
                    if (len(d.adds) < 20) and (len(d.adds) > 0):
                        log.info(f"adds  : {list(d.adds)}")

                if extras_dict['sync']:
                    if len(d.drops)+len(d.adds) > 0:
                        log.info('synchronizing ...')
                        d.synchronize()
                    else:
                        log.info("synchronizing not needed")
                else:
                    log.info('dry run, not performing synchronization')

        portal_timer._stop()
        log.info(f"PORTAL : {portal_timer.format}")

    # Perform EDS-Grouper synchronization for figshare quota
    if extras_dict['quota']:
        log.info("STAGE: QUOTA")
        quota_timer = TimerClass()
        quota_timer._start()

        quota_list  = ast.literal_eval(global_dict['quota_list'])
        quota_class = ast.literal_eval(global_dict['quota_class'])

        for q, c in zip(quota_list, quota_class):
            if 'ugrad' in c:
                log.info(f"Quota execution not required for {c} group. Skipping...")
                continue

            log.info(f"Working on {c} quota : {q} bytes")

            group_check = ga.check_group_exists(str(q), 'quota')
            if not group_check:  # Avoid execution
                log.warning(f"!!! Grouper quota NOT found : {q} !!!")
                continue

            log.info(f"Grouper quota exists : {q}")

            # LDAP query to retrieve members
            ldap_queries = quota.ual_ldap_quota_query(c, org_codes=org_codes)
            ldap_members = ldap_query.ldap_search(ldc, ldap_queries)
            log.info(f"EDS before {len(ldap_members)}")

            # Update based on CSV manual input files
            if mo_status:
                ldap_members = mo.identify_changes(ldap_members, q, 'quota')
            log.info(f" EDS size {len(ldap_members)}")

            # Grouper query
            grouper_quota = figshare_group(q, 'quota', production=grouper_production)
            log.info(f"Grouper group : {grouper_quota}")
            grouper_query_dict = ga.query(grouper_quota)
            log.info(f" Grouper size {len(grouper_query_dict['members'])}")

            # For --org_codes or --groups, only add users
            if not isinstance(org_codes, type(None)):
                log.info("Special mode with --org_codes --groups. Adding users only")
                # Combine grouper members with new ldap members
                ldap_members = set.union(grouper_query_dict['members'],
                                         ldap_members)

            # Delta between LDAP and Grouper
            d = delta.Delta(ldap_members=ldap_members,
                            grouper_query_dict=grouper_query_dict,
                            **delta_dict,
                            log=log)

            summary_dict[q] = \
                get_summary_dict(ldap_members,
                                 grouper_query_dict['members'], d)

            log.info(f"ldap and grouper have {len(d.common)} members in common")
            log.info(f"synchronization will drop {len(d.drops)} entries from grouper group")
            log.info(f"synchronization will add {len(d.adds)} entries to grouper group")
            if not extras_dict['ci']:
                if (len(d.drops) < 20) and (len(d.drops) > 0):
                    log.info(f"drops : {list(d.drops)}")
                if (len(d.adds) < 20) and (len(d.adds) > 0):
                    log.info(f"adds  : {list(d.adds)}")

            if extras_dict['sync']:
                if len(d.drops) + len(d.adds) > 0:
                    log.info('synchronizing ...')
                    d.synchronize()
                else:
                    log.info("synchronizing not needed")
            else:
                log.info('dry run, not performing synchronization')

        quota_timer._stop()
        log.info(f"QUOTA : {quota_timer.format}")

    # Perform EDS-Grouper synchronization for simple test
    if extras_dict['test'] or extras_dict['test_reverse']:
        log.info("STAGE: TEST")
        test_timer = TimerClass()
        test_timer._start()

        log.info("Working on test sync")

        # LDAP query to retrieve members
        test_uid = global_dict['uid']
        ldap_queries = ldap_query.uid_query(test_uid)
        log.info(f" test account : {test_uid}")

        ldap_members = set()
        if extras_dict['test']:
            ldap_members = ldap_query.ldap_search(ldc, ldap_queries)
            log.info(f" EDS size {len(ldap_members)}")
        if extras_dict['test_reverse']:
            log.info(" Providing empty member list")

        # Note testing is only performed on figshare:test and not figtest:test
        grouper_test = figshare_group('test', '')
        grouper_query_dict = ga.query(grouper_test)
        log.info(f" Grouper size {len(grouper_query_dict['members'])}")

        # Delta between LDAP and Grouper
        d = delta.Delta(ldap_members=ldap_members,
                        grouper_query_dict=grouper_query_dict,
                        **delta_dict, log=log)

        log.info(f"ldap and grouper have {len(d.common)} members in common")
        log.info(f"synchronization will drop {len(d.drops)} entries from grouper group")
        log.info(f"synchronization will add {len(d.adds)} entries to grouper group")
        if not extras_dict['ci']:
            if (len(d.drops) < 20) and (len(d.drops) > 0):
                log.info(f"drops : {list(d.drops)}")
            if (len(d.adds) < 20) and (len(d.adds) > 0):
                log.info(f"adds  : {list(d.adds)}")

        if extras_dict['sync']:
            if len(d.drops) + len(d.adds) > 0:
                log.info('synchronizing ...')
                d.synchronize()
            else:
                log.info("synchronizing not needed")
        else:
            log.info('dry run, not performing synchronization')

        test_timer._stop()
        log.info(f"TEST_SYNC : {test_timer.format}")

    main_timer._stop()
    log.info(main_timer.format)

    log.info("******************************")
    if extras_dict['portal'] or extras_dict['quota']:
        log.info("SUMMARY DATA")
        summary_df = pd.DataFrame.from_dict(summary_dict, orient='index')
        pandas_write_buffer(summary_df, log_filename)
    else:
        log.info("NO SUMMARY DATA")

    lc.script_end()

    lc.log_permission(path.join(log_dir, logfile))
